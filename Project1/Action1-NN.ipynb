{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('used_car_train_20200313.csv', sep = ' ')\n",
    "test_data = pd.read_csv('used_car_testB_20200421.csv', sep = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   SaleID             150000 non-null  int64  \n",
      " 1   name               150000 non-null  int64  \n",
      " 2   regDate            150000 non-null  int64  \n",
      " 3   model              149999 non-null  float64\n",
      " 4   brand              150000 non-null  int64  \n",
      " 5   bodyType           145494 non-null  float64\n",
      " 6   fuelType           141320 non-null  float64\n",
      " 7   gearbox            144019 non-null  float64\n",
      " 8   power              150000 non-null  int64  \n",
      " 9   kilometer          150000 non-null  float64\n",
      " 10  notRepairedDamage  150000 non-null  object \n",
      " 11  regionCode         150000 non-null  int64  \n",
      " 12  seller             150000 non-null  int64  \n",
      " 13  offerType          150000 non-null  int64  \n",
      " 14  creatDate          150000 non-null  int64  \n",
      " 15  price              150000 non-null  int64  \n",
      " 16  v_0                150000 non-null  float64\n",
      " 17  v_1                150000 non-null  float64\n",
      " 18  v_2                150000 non-null  float64\n",
      " 19  v_3                150000 non-null  float64\n",
      " 20  v_4                150000 non-null  float64\n",
      " 21  v_5                150000 non-null  float64\n",
      " 22  v_6                150000 non-null  float64\n",
      " 23  v_7                150000 non-null  float64\n",
      " 24  v_8                150000 non-null  float64\n",
      " 25  v_9                150000 non-null  float64\n",
      " 26  v_10               150000 non-null  float64\n",
      " 27  v_11               150000 non-null  float64\n",
      " 28  v_12               150000 non-null  float64\n",
      " 29  v_13               150000 non-null  float64\n",
      " 30  v_14               150000 non-null  float64\n",
      "dtypes: float64(20), int64(10), object(1)\n",
      "memory usage: 35.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    111361\n",
       "-       24324\n",
       "1.0     14315\n",
       "Name: notRepairedDamage, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['notRepairedDamage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 因为有-值，所以对它进行替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['notRepairedDamage'].replace('-','0.0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    135685\n",
       "1.0     14315\n",
       "Name: notRepairedDamage, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['notRepairedDamage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['notRepairedDamage'] = train_data['notRepairedDamage'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 同样清洗测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['notRepairedDamage'].replace('-','0.0',inplace=True)\n",
    "test_data['notRepairedDamage'].value_counts()\n",
    "test_data['notRepairedDamage'] = train_data['notRepairedDamage'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 继续清洗训练集，查看其他数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    150000.000000\n",
       "mean        119.316547\n",
       "std         177.168419\n",
       "min           0.000000\n",
       "25%          75.000000\n",
       "50%         110.000000\n",
       "75%         150.000000\n",
       "max       19312.000000\n",
       "Name: power, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['power'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 因为这里power的最大值超过了600，不符合题目中对于power最大值的范围，所以把超过600的值全部设置为600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guoxi\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    150000.000000\n",
       "mean        116.860973\n",
       "std          70.075256\n",
       "min           0.000000\n",
       "25%          75.000000\n",
       "50%         110.000000\n",
       "75%         150.000000\n",
       "max         600.000000\n",
       "Name: power, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['power'][train_data['power'] > 600] = 600\n",
    "train_data['power'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 对test数据同样进行修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guoxi\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    50000.00000\n",
       "mean       116.51788\n",
       "std         70.48107\n",
       "min          0.00000\n",
       "25%         75.00000\n",
       "50%        110.00000\n",
       "75%        150.00000\n",
       "max        600.00000\n",
       "Name: power, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['power'][test_data['power'] > 600] = 600\n",
    "test_data['power'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 添加缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fillna(train_data.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SaleID               0\n",
       "name                 0\n",
       "regDate              0\n",
       "model                0\n",
       "brand                0\n",
       "bodyType             0\n",
       "fuelType             0\n",
       "gearbox              0\n",
       "power                0\n",
       "kilometer            0\n",
       "notRepairedDamage    0\n",
       "regionCode           0\n",
       "seller               0\n",
       "offerType            0\n",
       "creatDate            0\n",
       "price                0\n",
       "v_0                  0\n",
       "v_1                  0\n",
       "v_2                  0\n",
       "v_3                  0\n",
       "v_4                  0\n",
       "v_5                  0\n",
       "v_6                  0\n",
       "v_7                  0\n",
       "v_8                  0\n",
       "v_9                  0\n",
       "v_10                 0\n",
       "v_11                 0\n",
       "v_12                 0\n",
       "v_13                 0\n",
       "v_14                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SaleID               0\n",
       "name                 0\n",
       "regDate              0\n",
       "model                0\n",
       "brand                0\n",
       "bodyType             0\n",
       "fuelType             0\n",
       "gearbox              0\n",
       "power                0\n",
       "kilometer            0\n",
       "notRepairedDamage    0\n",
       "regionCode           0\n",
       "seller               0\n",
       "offerType            0\n",
       "creatDate            0\n",
       "v_0                  0\n",
       "v_1                  0\n",
       "v_2                  0\n",
       "v_3                  0\n",
       "v_4                  0\n",
       "v_5                  0\n",
       "v_6                  0\n",
       "v_7                  0\n",
       "v_8                  0\n",
       "v_9                  0\n",
       "v_10                 0\n",
       "v_11                 0\n",
       "v_12                 0\n",
       "v_13                 0\n",
       "v_14                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.fillna(test_data.median(), inplace=True)\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 提取特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('SaleID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'regDate',\n",
       " 'model',\n",
       " 'brand',\n",
       " 'bodyType',\n",
       " 'fuelType',\n",
       " 'gearbox',\n",
       " 'power',\n",
       " 'kilometer',\n",
       " 'notRepairedDamage',\n",
       " 'regionCode',\n",
       " 'seller',\n",
       " 'offerType',\n",
       " 'creatDate',\n",
       " 'v_0',\n",
       " 'v_1',\n",
       " 'v_2',\n",
       " 'v_3',\n",
       " 'v_4',\n",
       " 'v_5',\n",
       " 'v_6',\n",
       " 'v_7',\n",
       " 'v_8',\n",
       " 'v_9',\n",
       " 'v_10',\n",
       " 'v_11',\n",
       " 'v_12',\n",
       " 'v_13',\n",
       " 'v_14']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 对特征做归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = min_max_scaler.fit_transform(train_data[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['price'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 下面的代码在之前的测试中因为错误的直接复制了上面的代码导致使用了fit.transform而不是transform，\n",
    "##### 所以一开始的预测结果很不好，超过了2000，修正之后结果来到了600以内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = min_max_scaler.transform(test_data[features].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数据集切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(250, activation='relu', input_shape=[len(features)]),\n",
    "    keras.layers.Dense(250, activation='relu'),\n",
    "    keras.layers.Dense(250, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 这里epochs设置成40次是因为担心过拟合，因为课上200次的迭代使得最后的线上预测达到了1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples\n",
      "Epoch 1/40\n",
      "120000/120000 [==============================] - 1s 11us/sample - loss: 4885.3599\n",
      "Epoch 2/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 2680.4721\n",
      "Epoch 3/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 1250.6277\n",
      "Epoch 4/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 1068.1545\n",
      "Epoch 5/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 978.5483\n",
      "Epoch 6/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 917.3996\n",
      "Epoch 7/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 872.3118\n",
      "Epoch 8/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 835.8788\n",
      "Epoch 9/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 807.3320\n",
      "Epoch 10/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 779.9807\n",
      "Epoch 11/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 757.5165\n",
      "Epoch 12/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 736.5479\n",
      "Epoch 13/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 716.7141\n",
      "Epoch 14/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 697.3890\n",
      "Epoch 15/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 681.8186\n",
      "Epoch 16/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 666.6042\n",
      "Epoch 17/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 651.0581\n",
      "Epoch 18/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 639.2180\n",
      "Epoch 19/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 629.9850\n",
      "Epoch 20/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 619.7305\n",
      "Epoch 21/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 612.2661\n",
      "Epoch 22/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 604.6831\n",
      "Epoch 23/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 600.4478\n",
      "Epoch 24/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 593.5496\n",
      "Epoch 25/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 589.5538\n",
      "Epoch 26/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 587.3012\n",
      "Epoch 27/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 581.2716\n",
      "Epoch 28/40\n",
      "120000/120000 [==============================] - ETA: 0s - loss: 576.884 - 0s 2us/sample - loss: 578.0352\n",
      "Epoch 29/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 577.9812\n",
      "Epoch 30/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 574.2070\n",
      "Epoch 31/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 574.5344\n",
      "Epoch 32/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 569.7819\n",
      "Epoch 33/40\n",
      "120000/120000 [==============================] - 0s 2us/sample - loss: 569.1932\n",
      "Epoch 34/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 564.9964\n",
      "Epoch 35/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 563.1640\n",
      "Epoch 36/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 563.3182\n",
      "Epoch 37/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 561.0263\n",
      "Epoch 38/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 559.9523\n",
      "Epoch 39/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 557.7339\n",
      "Epoch 40/40\n",
      "120000/120000 [==============================] - 0s 3us/sample - loss: 558.8057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2967685f8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'mean_absolute_error', optimizer = 'Adam')\n",
    "model.fit(train_x, train_y, batch_size = 1024, epochs = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用自己拆分的测试集看看模型的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集评估\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "测试集评估\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "568.1938425393502"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('训练集评估')\n",
    "mean_absolute_error(train_y,model(train_x))\n",
    "print('测试集评估')\n",
    "mean_absolute_error(test_y,model(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAE是568，证明模型效果还不错，使用所有数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150000 samples\n",
      "Epoch 1/40\n",
      "150000/150000 [==============================] - 1s 5us/sample - loss: 4659.9238\n",
      "Epoch 2/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 1939.6452\n",
      "Epoch 3/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 1132.8706\n",
      "Epoch 4/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 1013.3928\n",
      "Epoch 5/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 936.2113\n",
      "Epoch 6/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 877.5803\n",
      "Epoch 7/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 831.0612\n",
      "Epoch 8/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 792.4371\n",
      "Epoch 9/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 758.3467\n",
      "Epoch 10/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 731.7701\n",
      "Epoch 11/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 706.0825\n",
      "Epoch 12/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 684.6812\n",
      "Epoch 13/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 667.8829\n",
      "Epoch 14/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 651.4441\n",
      "Epoch 15/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 639.3092\n",
      "Epoch 16/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 628.6171\n",
      "Epoch 17/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 619.7612\n",
      "Epoch 18/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 609.1131\n",
      "Epoch 19/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 602.5404\n",
      "Epoch 20/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 595.1680\n",
      "Epoch 21/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 591.8082\n",
      "Epoch 22/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 582.3363\n",
      "Epoch 23/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 580.3438\n",
      "Epoch 24/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 574.8570\n",
      "Epoch 25/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 571.5249\n",
      "Epoch 26/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 566.0498\n",
      "Epoch 27/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 562.9731\n",
      "Epoch 28/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 560.1550\n",
      "Epoch 29/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 557.6368\n",
      "Epoch 30/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 554.4082\n",
      "Epoch 31/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 553.3637\n",
      "Epoch 32/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 551.4848\n",
      "Epoch 33/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 547.4873\n",
      "Epoch 34/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 546.0480\n",
      "Epoch 35/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 544.6253\n",
      "Epoch 36/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 541.8010\n",
      "Epoch 37/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 542.4265\n",
      "Epoch 38/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 541.9740\n",
      "Epoch 39/40\n",
      "150000/150000 [==============================] - 0s 3us/sample - loss: 538.3989\n",
      "Epoch 40/40\n",
      "150000/150000 [==============================] - 0s 2us/sample - loss: 540.5331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2f5d48be0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(250, activation='relu', input_shape=[len(features)]),\n",
    "    keras.layers.Dense(250, activation='relu'),\n",
    "    keras.layers.Dense(250, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'Adam')\n",
    "model.fit(x, y, batch_size = 1024, epochs = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 估计一下预测的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_stats(data):\n",
    "    print('min: ',np.min(data))\n",
    "    print('max: ',np.max(data))\n",
    "    print('ptp: ',np.ptp(data))\n",
    "    print('mean: ',np.mean(data))\n",
    "    print('std: ',np.std(data))\n",
    "    print('var: ',np.var(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集price的数据分布:\n",
      "min:  11\n",
      "max:  99999\n",
      "ptp:  99988\n",
      "mean:  5923.327333333334\n",
      "std:  7501.973469876635\n",
      "var:  56279605.942732885\n"
     ]
    }
   ],
   "source": [
    "print('训练集price的数据分布:')\n",
    "show_stats(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 通过下面的结果可以看出除了最小值之外，统计结果已经很接近测试数据了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经网络预测统计情况\n",
      "min:  -26.663393\n",
      "max:  96526.93\n",
      "ptp:  96553.59\n",
      "mean:  5802.2456\n",
      "std:  7296.553\n",
      "var:  53239692.0\n"
     ]
    }
   ],
   "source": [
    "print('神经网络预测统计情况')\n",
    "show_stats(Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 如果预测的统计情况和训练集的统计情况相近，则输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 将最大最小值限制在11-99999之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SaleID, price]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['SaleID'] = test_data['SaleID']\n",
    "result['price'] = Y_predict\n",
    "result.loc[result['price'] < 11, 'price'] = 12\n",
    "result[result['price'] < 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SaleID, price]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[result['price'] > 99999, 'price'] = 90000\n",
    "result[result['price'] > 99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:  12.0\n",
      "max:  96526.93\n",
      "ptp:  96514.93\n",
      "mean:  5802.247\n",
      "std:  7296.5522\n",
      "var:  53239670.0\n"
     ]
    }
   ],
   "source": [
    "show_stats(result['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 输出最终的预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./nn_ans.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
