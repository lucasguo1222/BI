{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新零售中的“人、货、场”分别指的是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 人就是指的用户，消费者。我们一般研究人的流量，转化率，客单价和复购率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 货可以归纳为D — M — S — B — b — C。\n",
    "\n",
    "#### D=Design（设计），指产品的设计过程；M=Manufacture（制造商），也有人称其为工厂；S=Supply Chain（供应链），通常指的是总代理、省代理、分销商、经销商等机构；B=Business（大B，商场），指的是大卖场、超市、连锁店等；b=business（小b，商店），指的是夫妻店、地摊、微商等个人销售者；C=Consumer（消费者），也就是最终端的客户。\n",
    "\n",
    "#### 以衣服为例，设计师（D）研究市场和用户设计出最流行的款式，然后把设计卖给制造商；制造商（M）开模、买原材料、设备，雇人把衣服做出来；通过各级代理、分销商、经销商等供应链企业（S）完成全国的铺货，建立库存；通过大商场（B），或者夫妻档口店，衣服陈列给消费者；最终，消费者（C）下单买到这件衣服"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过产品分析了解产品的浏览量，点击量，订单量，入蓝率，购买用户等信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 场：信息流+资金流+物流\n",
    "\n",
    "#### 那么场是如何把“人”和“货”连接起来的呢？任何可以被称作“零售”的完整的“场”，都有信息流、资金流和物流在其中不断连接、流动和交互。你进入商场挑选衣服的时候，就是获得了“信息流”。衣服的颜色、质地、款式和价格等信息决定你是否购买。当你决定要买的时候，去付钱的动作就完成了“资金流”的流转。当服务员打包好你的衣服，你选择自提带回家，就是“物流”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 还有比如渠道来源，页面分析，以及不同店面销售额，城市，商圈都是场"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIPL与传统的品牌资产评估有何区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIPL模型是把品牌在电商中的人群资产定量化的运营模型\n",
    "### A（Awareness），品牌认知人群。包括被品牌广告触达和品类词搜索的人；I（Interest），品牌兴趣人群。包括广告点击、浏览品牌/店铺主页、参与品牌互动、浏览产品详情页、品牌词搜索、领取试用、订阅/关注/入会、加购收藏的人；P（Purchase），品牌购买人群，指购买过品牌商品的人；L（Loyalty），品牌忠诚人群，包括复购、评论、分享的人。\n",
    "### AIPL的区别在于它是基于userid可以全链路的去做数据采集和分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 请列举一例生活工作中存在的帕累托法则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比如占所有人口不到20％的人，其所犯的罪占所有犯罪案的80％以上。 \n",
    "### 占全公司的数不到20％的业务员，其营业额为营业总额的80％；\n",
    "### 工作当中，20％的人请假占总请 假日数的80％。\n",
    "### 生活当中，20％的学生利用了教师80％的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 请简述GBDT与XGBoost的区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、XBG支持线性分类器\n",
    "#### 传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、XGB对损失函数进行二阶泰勒展开"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、xgboost在代价函数里加入了正则项，用于控制模型的复杂度\n",
    "#### 正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、XGB的权重衰减。\n",
    "#### xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、XGB支持列抽样。\n",
    "#### xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、xgboost工具支持并行。\n",
    "#### xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何处理神经网络中的过拟合问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 获取更多的数据\n",
    "#### 相当于是让模型尽可能的看到例外的情况，比如猫狗分类添加更多的不同种类的猫狗图片到原来的训练数据中\n",
    "#### 也可以使用数据增强，比如图像的旋转，伸缩，颜色明暗度的调整，添加高斯噪音等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 选择不同的模型\n",
    "#### 过拟合的原因可能是模型过于复杂，我们可以降低模型的复杂度。\n",
    "#### 试着减少网络层次，神经元个数（添加dropout技术）\n",
    "#### 增加噪声以及限制权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3模型融合\n",
    "#### 训练多个模型，取平均或者是加权平均的结果作为最后结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 贝叶斯方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
